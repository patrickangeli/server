name: Monitor Websites

on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  check-websites:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Create Jekyll site structure
        run: |
          mkdir -p docs
          cd docs
          # Criar estrutura b√°sica do Jekyll
          mkdir -p _layouts _includes _sass assets/css
          
          # Criar _config.yml
          echo "title: Website Monitor" > _config.yml
          echo "theme: jekyll-theme-minimal" >> _config.yml
          
          # Criar index.md
          echo "# Website Monitor" > index.md
          echo "## Latest Updates" >> index.md
          
          # Criar style.scss
          echo "---" > assets/css/style.scss
          echo "---" >> assets/css/style.scss
          echo "" >> assets/css/style.scss
          echo "@import \"{{ site.theme }}\";" >> assets/css/style.scss

      - name: Check websites for changes
        env:
          TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          WEBSITE_URLS: ${{ secrets.WEBSITE_URLS }}
        run: |
          import requests
          from bs4 import BeautifulSoup
          import os
          import hashlib
          import json
          from datetime import datetime

          # Configura√ß√£o dos diret√≥rios
          docs_dir = 'docs'
          if not os.path.exists(docs_dir):
              os.makedirs(docs_dir)

          # Arquivo de log
          log_file = os.path.join(docs_dir, 'changes.json')
          if not os.path.exists(log_file):
              with open(log_file, 'w') as f:
                  json.dump([], f)

          def send_telegram_message(message):
              token = os.environ['TELEGRAM_TOKEN']
              chat_id = os.environ['TELEGRAM_CHAT_ID']
              url = f"https://api.telegram.org/bot{token}/sendMessage"
              payload = {
                  "chat_id": chat_id,
                  "text": message,
                  "parse_mode": "HTML"
              }
              try:
                  response = requests.post(url, json=payload)
                  response.raise_for_status()
              except Exception as e:
                  print(f"Erro ao enviar mensagem: {str(e)}")

          def check_website(url):
              try:
                  headers = {
                      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                  }
                  response = requests.get(url, headers=headers, timeout=30)
                  response.raise_for_status()
                  soup = BeautifulSoup(response.text, 'html.parser')
                  return hashlib.md5(soup.get_text().encode()).hexdigest()
              except Exception as e:
                  print(f"Erro ao verificar {url}: {str(e)}")
                  return None

          # Carregar URLs
          websites = json.loads(os.environ['WEBSITE_URLS'])

          # Carregar hashes anteriores
          hash_file = os.path.join(docs_dir, 'last_hashes.json')
          try:
              with open(hash_file, 'r') as f:
                  last_hashes = json.load(f)
          except FileNotFoundError:
              last_hashes = {}

          current_hashes = {}
          updates = []
          timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

          for url in websites:
              current_hash = check_website(url)
              if current_hash:
                  current_hashes[url] = current_hash
                  if url not in last_hashes or current_hash != last_hashes[url]:
                      message = f"üîÑ <b>Atualiza√ß√£o Detectada!</b>\n\nüì± Site: {url}\n‚è∞ Data: {timestamp}"
                      updates.append(message)

          if updates:
              send_telegram_message("\n\n".join(updates))
              
              # Atualizar o arquivo de log
              with open(log_file, 'r+') as f:
                  logs = json.load(f)
                  for update in updates:
                      logs.append({
                          'timestamp': timestamp,
                          'update': update
                      })
                  f.seek(0)
                  f.truncate()
                  json.dump(logs, f, indent=2)

              # Atualizar index.md com as √∫ltimas altera√ß√µes
              with open(os.path.join(docs_dir, 'index.md'), 'w') as f:
                  f.write("# Website Monitor\n\n## Latest Updates\n\n")
                  for log in reversed(logs[-10:]):  # √öltimas 10 altera√ß√µes
                      f.write(f"- {log['timestamp']}: {log['update']}\n")

          # Salvar hashes atuais
          with open(hash_file, 'w') as f:
              json.dump(current_hashes, f, indent=2)

          if not updates:
              print(f"[{timestamp}] Nenhuma mudan√ßa detectada.")
        shell: python

      - name: Build with Jekyll
        uses: actions/jekyll-build-pages@v1
        with:
          source: ./docs
          destination: ./_site

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v2

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
